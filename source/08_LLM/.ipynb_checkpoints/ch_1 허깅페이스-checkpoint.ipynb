{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2159e66f",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">ch1_허깅페이스</span>\n",
    "\n",
    "- inference API 이용: 모델의 결과를 Surver 에서\n",
    "- pipeline() 이용 : 모델을 다운로드받아 결과를 local에서\n",
    "    * raw test -> tokenizer -> model -> [0.11, 0.55, 0.xx~] logits 값으로  prediction 결과 출력\n",
    "\n",
    "* 허깅페이스 transformer에서 지원하는 task\n",
    "\"sentiment-analysis\" = \"text-classification\"의 별칭(감정분석 전용으로 사용)\n",
    "\"text-classification\" : 감정분석, 뉴스분류, 리뷰 분류 등 일반적인 문장 분류\n",
    "\"zero-shot-classification\": 레이블을 학습 없이 주어진 후보군 중에서 분류\n",
    "\"token-classification\": 개채명 인식(NER ; Named Entity Recognition)등 단위라벨링\n",
    "\"ner : \"token-classification\"의 별칭\n",
    "\"text-generation\" : 텍스트 생성(GPT류 모델에 사용)\n",
    "\"text2text-generation\" : 번역, 요약등 입력 -> 출력 변환\n",
    "\"translation\" : 번역\n",
    "\"summarization\" : 텍스트요약\n",
    "\"quesiton-answering\" : 주어진 context들을 보고 질문에 답하기\n",
    "\"image-to-text\" : 그림을 설명\n",
    "\"image-classification\" : 이미지 분류\n",
    "\n",
    "## 텍스트 기반 감정분석 (긍정/부정)\n",
    " - c://사용자/컴퓨터명/.cache/huggingface/hub 에 모델 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7510e39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9516069889068604}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(task='sentiment-analysis') \n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "592b23c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598048329353333},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task=\"text-classification\",\n",
    "                     model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "# 감정분석시 내용이 많으면 list로\n",
    "classifier([\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b363d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.8578156232833862},\n",
       " {'label': 'POSITIVE', 'score': 0.9998821020126343}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"이 영화 정말 최고였어요. 감동적이고 연기가 대단해\",\n",
    "            \"This movie was the best. It's touching, and the acting is amazing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff1f7887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.8577605485916138}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"이 물건 정말 사고 싶어요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06e325bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998695850372314},\n",
       " {'label': 'POSITIVE', 'score': 0.999488353729248},\n",
       " {'label': 'NEGATIVE', 'score': 0.599323034286499},\n",
       " {'label': 'POSITIVE', 'score': 0.8669533729553223}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier([\"I like you\", \"I hat you\", \"나 너가 싫어\", \"힘들어요\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfd95af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9557898640632629},\n",
       " {'label': 'LABEL_0', 'score': 0.9092599749565125},\n",
       " {'label': 'LABEL_0', 'score': 0.9140236377716064},\n",
       " {'label': 'LABEL_1', 'score': 0.9714492559432983}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task = \"sentiment-analysis\",\n",
    "                     model=\"matthewburke/korean_sentiment\")\n",
    "classifier(['나는 너가 좋아','당신이 싫어요','힘들어요','오늘 기분이 최고야'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39a4e3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(task = \"sentiment-analysis\",\n",
    "                     model=\"matthewburke/korean_sentiment\")\n",
    "texts =['나는 너가 좋아','당신이 싫어요','힘들어요','오늘 기분이 최고야']\n",
    "result = classifier(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efb4a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a7c92df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 너가 좋아 => 긍정 : 0.9558\n",
      "당신이 싫어요 => 부정 : 0.9093\n",
      "힘들어요 => 부정 : 0.9140\n",
      "오늘 기분이 최고야 => 긍정 : 0.9714\n"
     ]
    }
   ],
   "source": [
    "for text, result in zip(texts, classifier(texts)):\n",
    "    label = \"긍정\" if result ['label']== \"LABEL_1\" else \"부정\"\n",
    "    print(f\"{text} => {label} : {result['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24318dcc",
   "metadata": {},
   "source": [
    "## 제로샷 분류 (Zero-shot분류)\n",
    " * 기계학습 및 자연어처리에서 각 개별 작업에 대한 특정 교육 없이 작업을 수행할 수 있는 모형(비지도학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9f9ec26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6a0a427dbd456d8a6f1e392b1bca46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimjh\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kimjh\\.cache\\huggingface\\hub\\models--facebook--bart-large-mnli. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b034cea159c84474935d232c2ae3bd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c2ea637bba4045baab931e348d29e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d8164d63a1475ea256ec769dc488ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3f6ffdbf71494eb047612400ccc37f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ac88c6ad36402ab52eb07e2f1f0d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I have a problem with my iphone that needs to be resolved asap!',\n",
       " 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'],\n",
       " 'scores': [0.5227575302124023,\n",
       "  0.45814022421836853,\n",
       "  0.014265153557062149,\n",
       "  0.002685002749785781,\n",
       "  0.0021520729642361403]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                     # model=\"facebook/bart-large-mnli\"\n",
    "                     )\n",
    "classifier(\n",
    "    \"I have a problem with my iphone that needs to be resolved asap!\",\n",
    "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73eb4b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'One day I well see the world',\n",
       " 'labels': ['travel', 'cooking', 'dancing'],\n",
       " 'scores': [0.9938076734542847, 0.0030999029986560345, 0.0030923611484467983]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_classify = \"One day I well see the world\"\n",
    "candidate_labels = ['travel', 'cooking', 'dancing']\n",
    "classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bad6905",
   "metadata": {},
   "source": [
    "# text 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0414aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8007a721bc754f718e6763d4fadf56ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimjh\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kimjh\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27876f5ddd2140268d08dc3c15da68e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbd135c2c924a1698495ba55d91be76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9958a07b7e13414e9bc38f024310cc54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688c01a83622413d8421f8f5e1217853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feeb508d591445f9b76b47c1cc2bd2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16229d24a1b1487697ec2598c5d70ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'in this course. We will teach you how to create, store and use a set of cryptographic tools to create and store Bitcoin addresses, and how to use them to make transactions and exchanges on the internet. You will also learn about how to create a secure, scalable, and secure Ethereum-based wallet, and how to upgrade your wallet to use an upgraded version of the ERC-20 standard. We will also teach you how to use the Ethereum protocol in the same way that we do with Bitcoin.\\n\\nPlease check out the full course description here.\\n\\nThe full course is available for $200. Click here to purchase it now.\\n\\nIf you enjoyed this course, please help us to continue to support it! You can help us by liking us on Facebook, or follow us on Twitter.\\n\\nIf you enjoyed this course, please consider donating to the Project Gutenberg EBook Project.\\n\\nIf you enjoyed this course, please consider donating to the Project Gutenberg EBook Project.\\n\\nYou can support this course by supporting us by disabling AdBlock or by providing a donation via PayPal.'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "# set_seed(2)\n",
    "generation = pipeline(\"text-generation\", \"gpt2\") # 텍스트 생성 gpt3부터는 허깅페이스없음\n",
    "generation(\n",
    "    \"in this course. We will teach you how to\",\n",
    "    pad_token_id=generation.tokenizer.eos_token_id\n",
    ") # pad_token_id 경고를 없애려고 setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3b3102c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this course. We will teach you how to create a set of rules for how to build a custom web application that will take advantage of a few of the core concepts of Rails and Rails' object oriented approach. We will then work with you to create a simple and concise and easy to use web app that will be used to create a custom website. We will teach you how to write and write user interactions that will be used by the user in the web application. We will also teach you how to create and edit content. We will see you write and edit content in the browser or on a tablet. You will learn how to use a web application to create new content, and how to control and manage it. You will learn how to write and edit content in a browser where you will not have to worry about having to type code into Google Chrome. In addition, we will learn how to create and edit templates and other documents. You will learn how to create a custom HTML template, and how to create an HTML file with any language. We will also learn how to create and edit pages, and how to edit pages from a browser. You will learn how to write and edit JavaScript code, and how to write code. We will learn how to create and edit HTML files, and how to create a page from a\n"
     ]
    }
   ],
   "source": [
    "result = generation(\n",
    "    \"in this course. We will teach you how to\",\n",
    "    pad_token_id=generation.tokenizer.eos_token_id\n",
    ") \n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdd235ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 과정은 다음과 같은 방법을 알려드려요. 해 수 있스서 세영데시도은 하지 나를 있스서 세영데시도은 하지 나를 있스서 세영데시도은 철스 그에 복스리선 나를 하지 나를 있스서 그에 복스리선 나를 하지 나를 있스서 세영데시도은 철스 그에 복스리선 나를 있\n"
     ]
    }
   ],
   "source": [
    "# generation = pipeline(\"text-generation\", \"gpt2\")\n",
    "result = generation(\n",
    "    \"이 과정은 다음과 같은 방법을 알려드려요. \",\n",
    "    pad_token_id = generation.tokenizer.eos_token_id\n",
    ")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cb1043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65219c42",
   "metadata": {},
   "source": [
    "# 4 마스크(빈칸) 채우기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9e42f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.19275671243667603,\n",
       "  'token': 3299,\n",
       "  'token_str': ' doctor',\n",
       "  'sequence': \"I'm going to hospital and meet a doctor\"},\n",
       " {'score': 0.06794622540473938,\n",
       "  'token': 27321,\n",
       "  'token_str': ' psychiatrist',\n",
       "  'sequence': \"I'm going to hospital and meet a psychiatrist\"},\n",
       " {'score': 0.06435572355985641,\n",
       "  'token': 16308,\n",
       "  'token_str': ' surgeon',\n",
       "  'sequence': \"I'm going to hospital and meet a surgeon\"},\n",
       " {'score': 0.05912882834672928,\n",
       "  'token': 9008,\n",
       "  'token_str': ' nurse',\n",
       "  'sequence': \"I'm going to hospital and meet a nurse\"},\n",
       " {'score': 0.05705604329705238,\n",
       "  'token': 1441,\n",
       "  'token_str': ' friend',\n",
       "  'sequence': \"I'm going to hospital and meet a friend\"},\n",
       " {'score': 0.03339698910713196,\n",
       "  'token': 18931,\n",
       "  'token_str': ' therapist',\n",
       "  'sequence': \"I'm going to hospital and meet a therapist\"},\n",
       " {'score': 0.030813172459602356,\n",
       "  'token': 12443,\n",
       "  'token_str': ' stranger',\n",
       "  'sequence': \"I'm going to hospital and meet a stranger\"},\n",
       " {'score': 0.02729799412190914,\n",
       "  'token': 26565,\n",
       "  'token_str': ' dentist',\n",
       "  'sequence': \"I'm going to hospital and meet a dentist\"},\n",
       " {'score': 0.02704632468521595,\n",
       "  'token': 1816,\n",
       "  'token_str': ' girl',\n",
       "  'sequence': \"I'm going to hospital and meet a girl\"},\n",
       " {'score': 0.024310709908604622,\n",
       "  'token': 3186,\n",
       "  'token_str': ' patient',\n",
       "  'sequence': \"I'm going to hospital and meet a patient\"}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(task = 'fill-mask',\n",
    "                   model = 'distilbert/distilroberta-base') #마스크 채우기\n",
    "unmasker(\"I'm going to hospital and meet a <mask>\",top_k =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79b4bf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.02659529447555542,\n",
       "  'token': 39547,\n",
       "  'token_str': ' nerd',\n",
       "  'sequence': \"Hello, I'm a nerd \"},\n",
       " {'score': 0.025217575952410698,\n",
       "  'token': 2378,\n",
       "  'token_str': ' fan',\n",
       "  'sequence': \"Hello, I'm a fan \"},\n",
       " {'score': 0.01737113669514656,\n",
       "  'token': 9916,\n",
       "  'token_str': ' robot',\n",
       "  'sequence': \"Hello, I'm a robot \"},\n",
       " {'score': 0.016277188435196877,\n",
       "  'token': 10746,\n",
       "  'token_str': ' reader',\n",
       "  'sequence': \"Hello, I'm a reader \"},\n",
       " {'score': 0.015000511892139912,\n",
       "  'token': 4910,\n",
       "  'token_str': ' guest',\n",
       "  'sequence': \"Hello, I'm a guest \"}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Hello, I'm a <mask> \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "336b9971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1413068026304245,\n",
       "  'token': 35,\n",
       "  'token_str': ':',\n",
       "  'sequence': '안녕하세요? 나는: 모델이예요.'},\n",
       " {'score': 0.12237928062677383,\n",
       "  'token': 116,\n",
       "  'token_str': '?',\n",
       "  'sequence': '안녕하세요? 나는? 모델이예요.'},\n",
       " {'score': 0.08188051730394363,\n",
       "  'token': 328,\n",
       "  'token_str': '!',\n",
       "  'sequence': '안녕하세요? 나는! 모델이예요.'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"안녕하세요? 나는 <mask> 모델이예요.\", top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2190e289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd5b4d83b0048b0afcddec096f0d0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimjh\\anaconda3\\envs\\ml-dl-nlp\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kimjh\\.cache\\huggingface\\hub\\models--google-bert--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff2a650741a467fbf570d35a82bec6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e211b0b26ec9493fbfb42ab47ed08256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601f875148b84b5d98b64dbe5369553d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd473d99d8e4736b6dd903d742cacc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.14414384961128235,\n",
       "  'token': 2535,\n",
       "  'token_str': 'role',\n",
       "  'sequence': \"hello, i ' m a role model.\"},\n",
       " {'score': 0.1417580246925354,\n",
       "  'token': 4827,\n",
       "  'token_str': 'fashion',\n",
       "  'sequence': \"hello, i ' m a fashion model.\"},\n",
       " {'score': 0.06221446394920349,\n",
       "  'token': 2047,\n",
       "  'token_str': 'new',\n",
       "  'sequence': \"hello, i ' m a new model.\"},\n",
       " {'score': 0.041028350591659546,\n",
       "  'token': 3565,\n",
       "  'token_str': 'super',\n",
       "  'sequence': \"hello, i ' m a super model.\"},\n",
       " {'score': 0.02591121383011341,\n",
       "  'token': 2449,\n",
       "  'token_str': 'business',\n",
       "  'sequence': \"hello, i ' m a business model.\"}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(task=\"fill-mask\",\n",
    "                   model=\"google-bert/bert-base-uncased\")\n",
    "unmasker(\"Hello, I'm a [MASK] model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d90535",
   "metadata": {},
   "source": [
    "# ※ InferenceAPI 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e3f411",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'HF_TOKEN'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m load_dotenv\n\u001b[1;32m----> 4\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHF_TOKEN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml-dl-nlp\\lib\\os.py:680\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    677\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[1;32m--> 680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'HF_TOKEN'"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv\n",
    "os.environ['HF_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032d680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93100726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b421b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cf9734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3577cd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01303231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e53220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c24e9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1b2981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202511ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d25e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47927de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac318ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp(ipykernel)",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
