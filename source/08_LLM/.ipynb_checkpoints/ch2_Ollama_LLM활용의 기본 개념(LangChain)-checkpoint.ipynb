{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c9f1aa7",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> ch2.Ollama_LLM활용의 기본개념(Lang Chain)</span>\n",
    "\n",
    "# 1. LLM을 활용하여 답변 생성하기\n",
    "## 1) Ollama를 이용한 로컬 LLM 이용 \n",
    "\n",
    "성능은 GPT, Claude같은 모델보다 떨어지나 개념설명을 위해 opensource 모델 활용\n",
    "\n",
    "### ollama.com 다운로드 -> 설치 -> 모델 pull\n",
    "\n",
    "cmd 창이나 powershell창에 ollama pull deepseek-r1:8b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a71e4e0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='일본의 수도는 도쿄입니다.' additional_kwargs={} response_metadata={'model': 'deepseek-r1:8b', 'created_at': '2025-12-09T02:23:43.2939061Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1346695200, 'load_duration': 45991900, 'prompt_eval_count': 10, 'prompt_eval_duration': 19002300, 'eval_count': 180, 'eval_duration': 1254105300, 'logprobs': None, 'model_name': 'deepseek-r1:8b', 'model_provider': 'ollama'} id='lc_run--019b00eb-f37a-7743-836d-ab4778fa5fef-0' usage_metadata={'input_tokens': 10, 'output_tokens': 180, 'total_tokens': 190}\t"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model = \"deepseek-r1:8b\")\n",
    "result = llm.invoke(\"일본의 수도는 어디야?\")\n",
    "print(result,end='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efa2b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d657da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7fd441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a51bc47e",
   "metadata": {},
   "source": [
    "### 모델 pull \n",
    " - cmd창이나 powershell창에서  ollama pull llama3.1:8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49847a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='도쿄입니다.', additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-12-09T02:23:33.4857946Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3519252000, 'load_duration': 1448021700, 'prompt_eval_count': 16, 'prompt_eval_duration': 2033241400, 'eval_count': 6, 'eval_duration': 35242300, 'logprobs': None, 'model_name': 'llama3.1:8b', 'model_provider': 'ollama'}, id='lc_run--019b00eb-c4ad-7c50-8d6c-fd0c42fcad77-0', usage_metadata={'input_tokens': 16, 'output_tokens': 6, 'total_tokens': 22})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model = \"llama3.1:8b\")\n",
    "result = llm.invoke(\"일본의 수도는 어디야\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea1ae51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "193513a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'타이베이'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b0eff8",
   "metadata": {},
   "source": [
    "# openai 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d572d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#환경변수 가져오기\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "# os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cebfd343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model = \"gpt-5-nano\",\n",
    "#                 api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "                )\n",
    "result = llm.invoke('What is the capital of Korea?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f573f6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There isn’t a single “capital of Korea.” It depends on which Korea you mean:\\n\\n- South Korea (Republic of Korea): Seoul\\n- North Korea (Democratic People’s Republic of Korea): Pyongyang\\n\\nIf you meant historical Korea before the division, different dynasties had different capitals (e.g., Joseon’s capital was Hanseong, now Seoul). Which Korea were you asking about?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b22484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Azure : OPEN_AI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4415e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloude 모델\n",
    "from langchain_anthropic import AnthropicLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c989460",
   "metadata": {},
   "source": [
    "# 2. 랭체인 스타일로 프롬프트 작성\n",
    " - 프롬프트 : llm 호출시 쓰는 질문\n",
    " - PromptValue, str, BaseMessages리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec36c5ef",
   "metadata": {},
   "source": [
    "## 1) 기본 프롬프트 템플릿 사용\n",
    " - PromptTemplate을 사용하여 변수가 포함된 템플릿을 작성하면 PromptValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c6e2772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느나라의 수도를 알고싶으신가요Russia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of Russia is Moscow.', additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-12-09T05:48:52.3911106Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1733566200, 'load_duration': 54569500, 'prompt_eval_count': 17, 'prompt_eval_duration': 1627994900, 'eval_count': 8, 'eval_duration': 47500500, 'logprobs': None, 'model_name': 'llama3.1:8b', 'model_provider': 'ollama'}, id='lc_run--019b01a7-c461-77d3-aa4c-1df93ee6cf43-0', usage_metadata={'input_tokens': 17, 'output_tokens': 8, 'total_tokens': 25})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "llm = ChatOllama(model = \"llama3.1:8b\")\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}?\", # {}안의 값을 새로운 값으로 대입 가능\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "country = input(\"어느나라의 수도를 알고싶으신가요\")\n",
    "prompt = prompt_template.invoke({\"country\":country})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0b94fa",
   "metadata": {},
   "source": [
    "## 2) 메시지 기반 프롬프트 작성\n",
    " - Basemessage 리스트\n",
    " - BaseMessage 상속받은 클래스 : AIMessage, HumanMessage, SystemMessage, ToolMessage\n",
    " - ctrl+shift+p --> python:select interpreter 입력 -> python환경선택\n",
    " - vscode에서 커널 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30d423d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You're referring to South Korea or North Korea?\\n\\nThe capital of South Korea is Seoul.\\n\\nThe capital of North Korea is Pyongyang.\", additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-12-09T06:04:57.4007663Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1649941000, 'load_duration': 1444930600, 'prompt_eval_count': 72, 'prompt_eval_duration': 22000400, 'eval_count': 27, 'eval_duration': 174042900, 'logprobs': None, 'model_name': 'llama3.1:8b', 'model_provider': 'ollama'}, id='lc_run--019b01b6-7e45-7b80-bf1f-f29fe4d0a23c-0', usage_metadata={'input_tokens': 72, 'output_tokens': 27, 'total_tokens': 99})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "message_list = [\n",
    "    SystemMessage(content=\"You are a helpful assistant\"), #페르소나 부여\n",
    "    HumanMessage(content = \"What is the capital of Italy?\"),#모범질문\n",
    "    AIMessage(content = \"The capital of Italy is Rome\"), #모범답안\n",
    "    HumanMessage(content = \"What is the capital of France?\"),#모범질문\n",
    "    AIMessage(content = \"The capital of France is Paris\"), #모범답안\n",
    "    HumanMessage(content=\"What is the capital of Korea\")\n",
    "]\n",
    "\n",
    "llm.invoke(message_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d71ec",
   "metadata": {},
   "source": [
    "## 3) ChatPromptTemplate사용\n",
    " - BaseMessgae리스트 -> 튜플리스트\n",
    " - PromptTemplate : 프롬프트에 변수 포함\n",
    " - ChatPromptTemplate : SystemPrompt설정(페르소나), few shot 설정, 변수포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c285e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라 수도가 궁금하세요Mongolia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of Mongolia is Ulaanbaatar.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "chatPrompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpfull assistant!\"),\n",
    "    ('human', \"What is the capital of Italy?\"), # 모범질문\n",
    "    (\"ai\", \"The capital of Italy is Rome.\"),    # 모범답안\n",
    "    ('human', \"What is the capital of France?\"), # 모범질문\n",
    "    (\"ai\", \"The capital of France is Paris.\"),    # 모범답안\n",
    "    (\"human\", \"What is the capital of {country}?\")\n",
    "])\n",
    "country = input(\"어느 나라 수도가 궁금하세요\")\n",
    "prompt = chatPrompt_template.invoke({\"country\": country})\n",
    "# print(\"프롬프트 : \", prompt, type(prompt))\n",
    "result = llm.invoke(prompt)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0213a38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라의 수도가 궁금하세요Mongolia\n",
      "messages=[SystemMessage(content='당신은 대한민국 정보 전문 도우미 입니다', additional_kwargs={}, response_metadata={}), HumanMessage(content='Mongolia의 수도는 어디인가요', additional_kwargs={}, response_metadata={})]\n",
      "몽골의 수도는 울란바토르입니다.\n"
     ]
    }
   ],
   "source": [
    "chatPromptTemplate = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"당신은 대한민국 정보 전문 도우미 입니다\"),\n",
    "    (\"human\", \"{country}의 수도는 어디인가요\")\n",
    "])\n",
    "\n",
    "country = input(\"어느 나라의 수도가 궁금하세요\")\n",
    "prompt = chatPromptTemplate.invoke({\"country\":country})\n",
    "print(prompt)\n",
    "result = llm.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2882c8b2",
   "metadata": {},
   "source": [
    "# 답변형식 컨트롤하기\n",
    "llm.invoke() 의 결과는 AIMessage() -> string이나 jsonm, 객체:OutputParser 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5085a1f9",
   "metadata": {},
   "source": [
    "## 1) 문자열 출력 파서 이용\n",
    "* StrOutputParser을 사용하여 LLM 출력(AIMessage)을 단순문자열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b774a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "#명시적인 지시사항이 포함된 프롬프트\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"what is the capital of {country}. return the name of the city only.\",\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "\n",
    "#프롬프트 템플릿에 값 주입\n",
    "prompt = prompt_template.invoke({\"country\":\"korea\"})\n",
    "\n",
    "# print(prompt)\n",
    "\n",
    "ai_message = llm.invoke(prompt)\n",
    "# print(ai_message)\n",
    "\n",
    "\n",
    "# 문자열 출력 파서를 이용하여 llm응답(AIMessage객체)d을 단순 문자열로 변환\n",
    "output_parser = StrOutputParser()\n",
    "result = output_parser.invoke(ai_message)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "949e64ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe51c709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The capital of Korea is Seoul. Specifically, Seoul is the capital of South Korea, whereas Pyongyang is the capital of North Korea. I'm a bit biased towards South Korea, but I can help with information about both countries if you'd like!\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#변수설정, system, few shot\n",
    "chat_prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant with expertise in South Korea!\"),\n",
    "    ('human', \"What is the capital of Italy?\"), # 모범질문\n",
    "    (\"ai\", \"Rome\"),    # 모범답안\n",
    "    ('human', \"What is the capital of France?\"), # 모범질문\n",
    "    (\"ai\", \"Paris\"),    # 모범답안\n",
    "    (\"human\", \"What is the capital of {country}?\")\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "output_parser.invoke(llm.invoke(chat_prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a68f147",
   "metadata": {},
   "source": [
    "## 2) json 출력  parser 이용\n",
    "* {'name':'홍길동','age':22}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5c669995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'capital': 'Seoul', 'population': '51,811,322', 'language': 'Korean', 'currency': 'South Korean won (KRW)'} <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "country_detail_prompt = PromptTemplate(\n",
    "    template = \"\"\"Give following information about {country}.\n",
    "    -capital\n",
    "    -population\n",
    "    -language\n",
    "    -currency\n",
    "    \n",
    "    Return it is JSON format and return that JSON dictionary only\"\"\",\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "\n",
    "prompt = country_detail_prompt.invoke({\"country\":\"Korea\"})\n",
    "ai_message = llm.invoke(prompt)\n",
    "# print(ai_message.content)\n",
    "output_parser = JsonOutputParser()\n",
    "json_result = output_parser.invoke(ai_message)\n",
    "print(json_result, type(json_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "085a91ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': 'Tokyo',\n",
       " 'population': 'approximately 128 million',\n",
       " 'language': 'Japanese',\n",
       " 'currency': 'Japanese Yen'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(country_detail_prompt.invoke({\"country\":\"Japan\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4012db7e",
   "metadata": {},
   "source": [
    "## 3) 구조화된 출력 사용\n",
    "- Pydantic 모델을 사용하여  LLM출력을 구조화된 형식으로 받기(JsonParser 보다 훨씬 안정적)\n",
    "- Pydantic : 데이터 유효성 검사, 설정관리를 간편하게 해주는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bcaf6b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.User object at 0x000001B607CFB400>\n"
     ]
    }
   ],
   "source": [
    "class User:\n",
    "    def __init__(self, id, name, is_active=True):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.is_active = is_active\n",
    "    \n",
    "user = User(1,\"홍길동\")\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ecd1ae83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=1 name='홍길동' is_active=True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pydantic import BaseModel, Field\n",
    "class User(BaseModel):\n",
    "    # gt=0:id>0 / ge=0:id>=0 / lt=0:id<0 / le=0:id<=0\n",
    "    id:int   = Field(gt=0,         description=\"id\")\n",
    "    name:str = Field(min_length=2, description=\"name\")\n",
    "    is_active:bool = Field(default=True, description=\"id활성화 여부\")\n",
    "user = User(id=\"1\", name=\"홍길동\")\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e5107aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountryDetail(capital='Seoul', population=51, language='Korean', currency='Won')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_detail_prompt = PromptTemplate(\n",
    "    template = \"\"\"Give following information about {country}.\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    Return in JSON format and return the JSON dictionary only\"\"\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "class CountryDetail(BaseModel): #description: 더 정확한 출력 유도\n",
    "    capital:str = Field(description = \"the Capital of the country\")\n",
    "    population:int = Field(description=\"the Population of the country\")\n",
    "    language:str = Field(description=\"the Language of the country\")\n",
    "    currency:str = Field(description=\"the currency of the country\")\n",
    "\n",
    "# 출력 형식 파서 + llm\n",
    "structedllm = llm.with_structured_output(CountryDetail)\n",
    "\n",
    "# llm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"}))\n",
    "\n",
    "info = structedllm.invoke(country_detail_prompt.invoke({\"country\":\"korea\"}))\n",
    "info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "05e9551a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Seoul', 51, 'Korean', 'Won')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.capital, info.population, info.language, info.currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fd2cce4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info를 Json으로 :  {\"capital\":\"Seoul\",\"population\":51,\"language\":\"Korean\",\"currency\":\"Won\"}\n",
      "info를 dict으로 :  {'capital': 'Seoul', 'population': 51, 'language': 'Korean', 'currency': 'Won'}\n",
      "info를 Jdict으로 :  {'capital': 'Seoul', 'population': 51, 'language': 'Korean', 'currency': 'Won'}\n"
     ]
    }
   ],
   "source": [
    "print(\"info를 Json으로 : \", info.model_dump_json())\n",
    "print(\"info를 dict으로 : \", info.model_dump())\n",
    "print(\"info를 Jdict으로 : \", info.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "96775d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(info.model_dump_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e32af3a",
   "metadata": {},
   "source": [
    "# 4. LCEL을 활용한 렝체인 생성하기\n",
    "## 1) 문자열 출력 파서 사용\n",
    " - invoke\n",
    " - StrOutputParser, ChatOllama, PromptTemplate등은 모두 XXX로 상속"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "151ebdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOllama(model = \"llama3.1:8b\",\n",
    "                temperature = 0 ) #일관된 답변(보수적인 답변)\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}. return the name of the city only\",\n",
    "    input_variables= [\"country\"]\n",
    ")\n",
    "output_parser = StrOutputParser() #AIMessage()를  str 변환\n",
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3d3553",
   "metadata": {},
   "source": [
    "## 2) LCEL을 사용한 간단한 체인 구성\n",
    " - 파이프 연산자 (L) 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "de005f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#프롬프트 템플릿 -> llm ->  출력파서를 연결하는 체인 생성\n",
    "capital_chain = prompt_template | llm | output_parser\n",
    "#생성된 체인 invoke\n",
    "capital_chain.invoke({\"country\":\"korea\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b483a1d",
   "metadata": {},
   "source": [
    "# 3) 복합체인 구성\n",
    " - 여러 단계의 추론이 필요한 경우(체인 연결)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1b17a852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라 설명 -> 나라이름\n",
    "country_prompt = PromptTemplate(\n",
    "    template = \"\"\"Guess the name of the country based on the following informat:\n",
    "    {information}\n",
    "    Return the name of the country only\"\"\",\n",
    "    input_variables=[\"information\"]\n",
    ")\n",
    "output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\":\n",
    "                                                       \"this country is known for its food?\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5b08cb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라명 추출 체인 생성\n",
    "country_chain = country_prompt |llm | output_parser\n",
    "country_chain.invoke({'information': \"this country is very famous for its wine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "26617de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#복합체인 : 나라설명 => 나라명(country_chain)\n",
    "#                       나라명 -> 수도(capital_chain)\n",
    "final_chain = country_chain | capital_chain\n",
    "final_chain.invoke({\"information\":\"This country is very famous for its wine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8d70849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#v폭합체인 : informaiton -> country_chain -> (나라명을 country) -> capital_chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "final_chain = {\"information\" : RunnablePassthrough()} | \\\n",
    "{\"country\":country_chain} | capital_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6ae14e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke(\"this country is very famous for its wine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d291e0f8",
   "metadata": {},
   "source": [
    " - 한글 지원이 안되는 모델은 랭체인 연결이 잘 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d0d1c1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아르헨티나입니다.'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#나라 설명 -> 나라이름\n",
    "country_prompt = PromptTemplate(\n",
    "    template = \"\"\"다음의 {information} 설명을 보고 나라이름을 맞춰봐:\n",
    "    {information}\n",
    "    나라이름만 한국어로 return 해줘\"\"\",\n",
    "    input_variable=[\"information\"]\n",
    ")\n",
    "output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\":\"이나라는 와인으로 유명해\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0d5d605d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'France'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\":\"이 나라는 와인으로 유명해\"})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
